{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットをモデルに入れるための準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要なもののインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データリスト関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDataList(csv_path):\n",
    "    datalist = pd.read_csv(csv_path)\n",
    "    datalist = datalist.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1)　\n",
    "    datalist = pd.get_dummies(datalist)\n",
    "    datalist = datalist.fillna(-1)\n",
    "    return datalist\n",
    "datalist = makeDataList(\"../dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"datalist.values[0] =\", datalist.values[0])\n",
    "datalist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_datalist, val_datalist = train_test_split(datalist, test_size=0.1, random_state=1234, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"len(train_datalist) =\", len(train_datalist))\n",
    "print(\"len(val_datalist) =\", len(val_datalist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データリスト関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetMaker(data.Dataset):\n",
    "    def __init__(self, datalist):\n",
    "        self.input_datalist = datalist.drop([\"PassengerId\", \"Survived\"], axis=1).values.astype(np.float32)\n",
    "        self.label_datalist = datalist[\"Survived\"].values.astype(np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_datalist)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.input_datalist[index]\n",
    "        labels = self.label_datalist[index]\n",
    "        return inputs, labels\n",
    "\n",
    "dataset = DatasetMaker(datalist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dataset.__len__() =\", dataset.__len__())\n",
    "print(\"dataset.__getitem__(index=0)[0] =\", dataset.__getitem__(index=0)[0])\n",
    "print(\"dataset.__getitem__(index=0)[1] =\", dataset.__getitem__(index=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データローダーの確認\n",
    " torch.utils.data.DataLoader()を呼び出すと使える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "batch_itr = iter(dataloader)\n",
    "inputs, labels = next(batch_itr)\n",
    "\n",
    "print(\"inputs =\\n\", inputs)\n",
    "print(\"inputs.size() =\", inputs.size())\n",
    "print(\"labels =\", labels)\n",
    "print(\"labels.size() =\", labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ネットワーククラスの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, dim_inputs, dim_mid, dim_outputs, dropout_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(dim_inputs, dim_mid),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            \n",
    "            nn.Linear(dim_mid, dim_mid),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            \n",
    "            nn.Linear(dim_mid, dim_outputs)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "net = Network(len(dataset.__getitem__(index=0)[0]), 64, 2, dropout_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)\n",
    "outputs = net(inputs)\n",
    "print(\"outputs = \\n\", outputs)\n",
    "print(\"outputs.size() =\", outputs.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchがgpuを認識しているかの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda if torch.cuda.is_available() else \"N/A\")\n",
    "print(\"Number of CUDA devices:\", torch.cuda.device_count())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"CUDA Device {i}:\")\n",
    "        print(f\"  Name: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  Capability: {torch.cuda.get_device_capability(i)}\")\n",
    "        print(f\"  Total memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# GPUが利用可能な場合、簡単なテンソル演算をテスト実行\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\nPerforming a simple tensor operation on GPU:\")\n",
    "    x = torch.rand(5, 3)\n",
    "    print(x)\n",
    "    x = x.cuda()\n",
    "    print(x)\n",
    "    print(\"Tensor is on GPU:\", x.is_cuda)\n",
    "else:\n",
    "    print(\"\\nGPU is not available. PyTorch will use CPU.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainerクラスを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, csv_path, num_epochs, batch_size, lr, save_weights_path):\n",
    "        # デバイスの設定（GPUが利用可能な場合はGPU、そうでない場合はCPUを使用）\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"self.device =\", self.device)\n",
    "\n",
    "        # トレーニングのパラメータを設定\n",
    "        self.num_epochs = num_epochs\n",
    "        self.save_weights_path = save_weights_path\n",
    "\n",
    "        # データの準備\n",
    "        datalist = makeDataList(csv_path)  # CSVファイルからデータリストを作成\n",
    "        # データを訓練用と検証用に分割（90%訓練、10%検証）\n",
    "        train_datalist, val_datalist = train_test_split(datalist, test_size=0.1, random_state=1234, shuffle=True)\n",
    "        \n",
    "        # データセットとデータローダーの作成\n",
    "        train_dataset = DatasetMaker(train_datalist)\n",
    "        val_dataset = DatasetMaker(val_datalist)\n",
    "        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "        \n",
    "        # データローダーを辞書にまとめる\n",
    "        self.dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "\n",
    "        # ネットワークモデルの初期化\n",
    "        self.net = Network(\n",
    "            dim_inputs = len(train_dataset.__getitem__(index=0)[0]),\n",
    "            dim_mid = 64,\n",
    "            dim_outputs = 2,\n",
    "            dropout_rate=0.1\n",
    "        )\n",
    "        self.net.to(self.device)  # モデルをGPUまたはCPUに移動\n",
    "\n",
    "        # 損失関数と最適化アルゴリズムの設定\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=lr)\n",
    "\n",
    "    def train(self):\n",
    "        # トレーニング開始時間の記録\n",
    "        start_clock = time.time()\n",
    "\n",
    "        # 損失の記録用辞書\n",
    "        record_loss_dict = {\"train\": [], \"val\": []}\n",
    "        min_loss_epoch = 0.0\n",
    "\n",
    "        # エポックのループ\n",
    "        for epoch in range(self.num_epochs):\n",
    "            if epoch == 0 or not (epoch+1) % (self.num_epochs // 10):\n",
    "                print(\"----------\")\n",
    "                print(\"Epoch {}/{}\".format(epoch+1, self.num_epochs))\n",
    "\n",
    "            # 訓練フェーズと検証フェーズのループ\n",
    "            for phase in [\"train\", \"val\"]:\n",
    "                # モデルのモード設定（訓練時はtrain、検証時はeval）\n",
    "                if phase == \"train\":\n",
    "                    self.net.train()\n",
    "                else:\n",
    "                    self.net.eval()\n",
    "\n",
    "                # 損失と入力数の初期化\n",
    "                loss_epoch = 0.0\n",
    "                num_inputs = 0\n",
    "\n",
    "                # ミニバッチのループ\n",
    "                for inputs, labels in self.dataloaders_dict[phase]:\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    labels = labels.to(self.device)\n",
    "\n",
    "                    # 勾配のリセット\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                    # 訓練時のみ勾配を計算\n",
    "                    with torch.set_grad_enabled(phase == \"train\"):\n",
    "                        # 順伝播\n",
    "                        outputs = self.net(inputs)\n",
    "                        loss = self.criterion(outputs, labels)\n",
    "\n",
    "                        # 訓練時は逆伝播と最適化\n",
    "                        if phase == \"train\":\n",
    "                            loss.backward()\n",
    "                            self.optimizer.step()\n",
    "\n",
    "                    # 損失の累積\n",
    "                    loss_epoch += loss.item() * inputs.size(0)\n",
    "                    num_inputs += inputs.size(0)\n",
    "\n",
    "                # エポックごとの平均損失を計算\n",
    "                loss_epoch = loss_epoch / num_inputs\n",
    "                record_loss_dict[phase].append(loss_epoch)\n",
    "\n",
    "                if epoch == 0 or not (epoch+1) % (self.num_epochs // 10):\n",
    "                    print(\"{} Loss: {:.4f}\".format(phase, loss_epoch))\n",
    "\n",
    "            # 最良モデルの保存\n",
    "            if epoch == 0 or record_loss_dict[\"val\"][-1] < min_loss_epoch:\n",
    "                min_loss_epoch = record_loss_dict[\"val\"][-1]\n",
    "                torch.save(self.net.state_dict(), self.save_weights_path)\n",
    "\n",
    "        # トレーニング終了時間の記録と表示\n",
    "        mins = (time.time() - start_clock) // 60\n",
    "        secs = (time.time() - start_clock) % 60\n",
    "        print (\"training time: \", mins, \" [min] \", secs, \" [sec]\")\n",
    "\n",
    "        # 損失のグラフ表示\n",
    "        self.showGraph(record_loss_dict)\n",
    "\n",
    "    def showGraph(self, record_loss_dict):\n",
    "        # 訓練と検証の損失をグラフ化\n",
    "        graph = plt.figure()\n",
    "        plt.plot(range(len(record_loss_dict[\"train\"])), record_loss_dict[\"train\"], label=\"Training\")\n",
    "        plt.plot(range(len(record_loss_dict[\"val\"])), record_loss_dict[\"val\"], label=\"Validation\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"last loss: train=\" + str(record_loss_dict[\"train\"][-1]) + \", val=\" + str(record_loss_dict[\"val\"][-1]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    csv_path = \"../dataset/train.csv\"\n",
    "    num_epochs = 2000\n",
    "    batch_size = 80\n",
    "    lr = 0.0001\n",
    "    save_weights_path = \"./weights.pth\"\n",
    "\n",
    "    trainer = Trainer(csv_path, num_epochs, batch_size, lr, save_weights_path)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題\n",
    " #### ・demo.ipynbの中身を機能ごとにcodeフォルダの中のmodel.py,train.py,utils.pyに分離して、train.pyを実行すると動くようにしてみましょう\n",
    "  #### *確認部分はなくていいです\n",
    " #### ・datasetの中のtest.csvを入力データとして実際の推論を行ってみましょう \n",
    "　\n",
    "  ##### test.csvにはSurvivedのラベルは無いので、読み込んで学習したモデルに入力し、出力をcsvファイルとしてresultフォルダに保存してください"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
